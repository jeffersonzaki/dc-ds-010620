{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier, AdaBoostRegressor, GradientBoostingClassifier\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the problems with using single decision trees and random forests is that, once I make a split, I can't go back and consider how another feature varies across the whole dataset. But suppose I were to consider **my tree's errors**. The fundamental idea of ***boosting*** is to start with a weak learner and then to use information about its errors to build a new model that can supplement the original model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two Types\n",
    "\n",
    "The two main types of boosting available in Scikit-Learn are adaptive boosting (AdaBoostClassifier, AdaBoostRegressor) and gradient boosting (GradientBoostingClassifier, GradientBoostingRegressor).\n",
    "\n",
    "Again, the fundamental idea of boosting is to use a sequence of **weak** learners to build a model. Though the individual learners are weak, the idea is to train iteratively in order to produce a better predictor. More specifically, the first learner will be trained on the data as it stands, but future learners will be trained on modified versions of the data. The point of the modifications is to highlight the \"hard-to-predict-accurately\" portions of the data.\n",
    "\n",
    "- **AdaBoost** works by iteratively adapting two related series of weights, one attached to the datapoints and the other attached to the learners themselves. Datapoints that are incorrectly classified receive greater weights for the next learner in the sequence. That way, future learners will be more likely to focus on those datapoints. At the end of the sequence, the learners that make better predictions, especially on the datapoints that are more resistant to correct classification, receive more weight in the final \"vote\" that determines the ensemble's prediction. <br/> Suppose we have binary classification problem and we represent the two classes with 1 and -1. (This is standard for describing the algorithm of AdaBoost.) <br/>\n",
    "Then, in a nutshell: <br/>\n",
    "    1. Train a weak learner. <br/>\n",
    "    2. Calculate its error $\\epsilon$. <br/>\n",
    "    3. Use that error as a weight on the classifier: $\\theta = \\frac{1}{2}ln\\left(\\frac{1-\\epsilon}{\\epsilon}\\right)$. <br/>\n",
    "    Note that $\\theta$ CAN be negative. This represents a classifier whose accuracy is _worse_ than chance. <br/>\n",
    "    4. Use _that_ to adjust the data points' weights: $w_{n+1} = w_n\\left(\\frac{e^{\\pm\\theta}}{scaler}\\right)$. Use $+\\theta$ for incorrect predictions, $-\\theta$ for correct predictions. <br/>  $\\rightarrow$ For more detail on AdaBoost, see [here](https://towardsdatascience.com/boosting-algorithm-adaboost-b6737a9ee60c).\n",
    "\n",
    "- **Gradient Boosting** works instead by training each new learner on the residuals of the model built with the learners that have so far been constructed. That is, Model $n+1$ (with $n+1$ learners) will focus on the predictions of Model $n$ (with only $n$ learners) that were **most off the mark**. As the training process repeats, the learners learn and the residuals get smaller. I would get a sequence going: <br/> Model 0 is very simple. Perhaps it merely predicts the mean: <br/>\n",
    "$\\hat{y}_0 = \\bar{y}$; <br/>\n",
    "Model 1's predictions would then be the sum of (i) Model 0's predictions and (ii) the predictions of the model fitted to Model 0's residuals: <br/> $\\hat{y}_1 = \\hat{y}_0 + \\hat{(y - \\hat{y})}_{err0}$; <br/>\n",
    "Now iterate: Model 2's predictions will be the sum of (i) Model 0's predictions, (ii) the predictions of the model fitted to Model 0's residuals, and (iii) the predictions of the model fitted to Model 1's residuals: <br/> $\\hat{y}_2 = \\hat{y}_0 + \\hat{(y - \\hat{y})}_{err0} + \\hat{(y - \\hat{y})}_{err1}$<br/>\n",
    "Etc.\n",
    "<br/>\n",
    "\n",
    "For more on this idea, see [here](http://blog.kaggle.com/2017/01/23/a-kaggle-master-explains-gradient-boosting/). <br/> $\\rightarrow$ How does gradient boosting work for a classification problem? How do we even make sense of the notion of a gradient in that context? The short answer is that we appeal to the probabilities associated with the predictions for the various classes. See more on this topic [here](https://sefiks.com/2018/10/29/a-step-by-step-gradient-boosting-example-for-classification/). <br/> $\\rightarrow$ Why is this called \"_gradient_ boosting\"? The short answer is that fitting a learner to a model's residuals comes to the same things as fitting it to the derivative of that model's loss function. See more on this topic [here](https://www.ritchievink.com/blog/2018/11/19/algorithm-breakdown-why-do-we-call-it-gradient-boosting/).\n",
    "\n",
    "## AdaBoost in Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nr</th>\n",
       "      <th>Rmag</th>\n",
       "      <th>e.Rmag</th>\n",
       "      <th>ApDRmag</th>\n",
       "      <th>mumax</th>\n",
       "      <th>Mcz</th>\n",
       "      <th>e.Mcz</th>\n",
       "      <th>MCzml</th>\n",
       "      <th>chi2red</th>\n",
       "      <th>UjMAG</th>\n",
       "      <th>...</th>\n",
       "      <th>UFS</th>\n",
       "      <th>e.UFS</th>\n",
       "      <th>BFS</th>\n",
       "      <th>e.BFS</th>\n",
       "      <th>VFD</th>\n",
       "      <th>e.VFD</th>\n",
       "      <th>RFS</th>\n",
       "      <th>e.RFS</th>\n",
       "      <th>IFD</th>\n",
       "      <th>e.IFD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>24.995</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.935</td>\n",
       "      <td>24.214</td>\n",
       "      <td>0.832</td>\n",
       "      <td>0.036</td>\n",
       "      <td>1.400</td>\n",
       "      <td>0.64</td>\n",
       "      <td>-17.67</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01870</td>\n",
       "      <td>0.00239</td>\n",
       "      <td>0.01630</td>\n",
       "      <td>0.00129</td>\n",
       "      <td>0.017300</td>\n",
       "      <td>0.00141</td>\n",
       "      <td>0.01650</td>\n",
       "      <td>0.000434</td>\n",
       "      <td>0.02470</td>\n",
       "      <td>0.00483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>25.013</td>\n",
       "      <td>0.181</td>\n",
       "      <td>-0.135</td>\n",
       "      <td>25.303</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.41</td>\n",
       "      <td>-18.28</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00706</td>\n",
       "      <td>0.00238</td>\n",
       "      <td>0.00420</td>\n",
       "      <td>0.00115</td>\n",
       "      <td>0.003930</td>\n",
       "      <td>0.00182</td>\n",
       "      <td>0.00723</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.00973</td>\n",
       "      <td>0.00460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>24.246</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.821</td>\n",
       "      <td>23.511</td>\n",
       "      <td>1.202</td>\n",
       "      <td>0.037</td>\n",
       "      <td>1.217</td>\n",
       "      <td>0.92</td>\n",
       "      <td>-19.75</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01260</td>\n",
       "      <td>0.00184</td>\n",
       "      <td>0.01830</td>\n",
       "      <td>0.00115</td>\n",
       "      <td>0.018800</td>\n",
       "      <td>0.00167</td>\n",
       "      <td>0.02880</td>\n",
       "      <td>0.000655</td>\n",
       "      <td>0.05700</td>\n",
       "      <td>0.00465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>25.203</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.639</td>\n",
       "      <td>24.948</td>\n",
       "      <td>0.912</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.776</td>\n",
       "      <td>0.39</td>\n",
       "      <td>-17.83</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01410</td>\n",
       "      <td>0.00186</td>\n",
       "      <td>0.01180</td>\n",
       "      <td>0.00110</td>\n",
       "      <td>0.009670</td>\n",
       "      <td>0.00204</td>\n",
       "      <td>0.01050</td>\n",
       "      <td>0.000416</td>\n",
       "      <td>0.01340</td>\n",
       "      <td>0.00330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26</td>\n",
       "      <td>25.504</td>\n",
       "      <td>0.112</td>\n",
       "      <td>-1.588</td>\n",
       "      <td>24.934</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.067</td>\n",
       "      <td>1.330</td>\n",
       "      <td>1.45</td>\n",
       "      <td>-17.69</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00514</td>\n",
       "      <td>0.00170</td>\n",
       "      <td>0.00102</td>\n",
       "      <td>0.00127</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.00160</td>\n",
       "      <td>0.00139</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.00590</td>\n",
       "      <td>0.00444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Nr    Rmag  e.Rmag  ApDRmag   mumax    Mcz  e.Mcz  MCzml  chi2red  UjMAG  \\\n",
       "0   6  24.995   0.097    0.935  24.214  0.832  0.036  1.400     0.64 -17.67   \n",
       "1   9  25.013   0.181   -0.135  25.303  0.927  0.122  0.864     0.41 -18.28   \n",
       "2  16  24.246   0.054    0.821  23.511  1.202  0.037  1.217     0.92 -19.75   \n",
       "3  21  25.203   0.128    0.639  24.948  0.912  0.177  0.776     0.39 -17.83   \n",
       "4  26  25.504   0.112   -1.588  24.934  0.848  0.067  1.330     1.45 -17.69   \n",
       "\n",
       "   ...      UFS    e.UFS      BFS    e.BFS       VFD    e.VFD      RFS  \\\n",
       "0  ...  0.01870  0.00239  0.01630  0.00129  0.017300  0.00141  0.01650   \n",
       "1  ...  0.00706  0.00238  0.00420  0.00115  0.003930  0.00182  0.00723   \n",
       "2  ...  0.01260  0.00184  0.01830  0.00115  0.018800  0.00167  0.02880   \n",
       "3  ...  0.01410  0.00186  0.01180  0.00110  0.009670  0.00204  0.01050   \n",
       "4  ...  0.00514  0.00170  0.00102  0.00127  0.000039  0.00160  0.00139   \n",
       "\n",
       "      e.RFS      IFD    e.IFD  \n",
       "0  0.000434  0.02470  0.00483  \n",
       "1  0.000500  0.00973  0.00460  \n",
       "2  0.000655  0.05700  0.00465  \n",
       "3  0.000416  0.01340  0.00330  \n",
       "4  0.000499  0.00590  0.00444  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "galaxies = pd.read_csv('COMBO17.csv')\n",
    "galaxies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a dataset about galaxies. The Mcz and MCzml columns are measures of redshift, which is our target. Mcz is usually understood to be a better measure, so that will be our target column. Many of the other columns have to do with various measures of galaxies' magnitudes. For more on the dataset, see [here](https://astrostatistics.psu.edu/datasets/COMBO17.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Nr', 'Rmag', 'e.Rmag', 'ApDRmag', 'mumax', 'Mcz', 'e.Mcz', 'MCzml',\n",
       "       'chi2red', 'UjMAG', 'e.UjMAG', 'BjMAG', 'e.BjMAG', 'VjMAG', 'e.VjMAG',\n",
       "       'usMAG', 'e.usMAG', 'gsMAG', 'e.gsMAG', 'rsMAG', 'e.rsMAG', 'UbMAG',\n",
       "       'e.UbMAG', 'BbMAG', 'e.BbMAG', 'VnMAG', 'e.VbMAG', 'S280MAG',\n",
       "       'e.S280MA', 'W420FE', 'e.W420FE', 'W462FE', 'e.W462FE', 'W485FD',\n",
       "       'e.W485FD', 'W518FE', 'e.W518FE', 'W571FS', 'e.W571FS', 'W604FE',\n",
       "       'e.W604FE', 'W646FD', 'e.W646FD', 'W696FE', 'e.W696FE', 'W753FE',\n",
       "       'e.W753FE', 'W815FS', 'e.W815FS', 'W856FD', 'e.W856FD', 'W914FD',\n",
       "       'e.W914FD', 'W914FE', 'e.W914FE', 'UFS', 'e.UFS', 'BFS', 'e.BFS', 'VFD',\n",
       "       'e.VFD', 'RFS', 'e.RFS', 'IFD', 'e.IFD'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "galaxies.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "galaxies.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "galaxies = galaxies.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's collect together the columns that have high correlation with Mcz, our target:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "for ind in galaxies.corr()['Mcz'].index:\n",
    "    if abs(galaxies.corr()['Mcz'][ind]) > 0.5:\n",
    "        preds.append(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mcz</th>\n",
       "      <th>e.Mcz</th>\n",
       "      <th>MCzml</th>\n",
       "      <th>UjMAG</th>\n",
       "      <th>BjMAG</th>\n",
       "      <th>VjMAG</th>\n",
       "      <th>usMAG</th>\n",
       "      <th>gsMAG</th>\n",
       "      <th>rsMAG</th>\n",
       "      <th>UbMAG</th>\n",
       "      <th>BbMAG</th>\n",
       "      <th>VnMAG</th>\n",
       "      <th>S280MAG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mcz</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.613071</td>\n",
       "      <td>0.872016</td>\n",
       "      <td>-0.699550</td>\n",
       "      <td>-0.628226</td>\n",
       "      <td>-0.641983</td>\n",
       "      <td>-0.698304</td>\n",
       "      <td>-0.652170</td>\n",
       "      <td>-0.631398</td>\n",
       "      <td>-0.699731</td>\n",
       "      <td>-0.659506</td>\n",
       "      <td>-0.641870</td>\n",
       "      <td>-0.700453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e.Mcz</th>\n",
       "      <td>0.613071</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.590179</td>\n",
       "      <td>-0.170296</td>\n",
       "      <td>-0.122309</td>\n",
       "      <td>-0.122616</td>\n",
       "      <td>-0.168326</td>\n",
       "      <td>-0.126491</td>\n",
       "      <td>-0.114022</td>\n",
       "      <td>-0.170208</td>\n",
       "      <td>-0.130680</td>\n",
       "      <td>-0.122546</td>\n",
       "      <td>-0.169344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCzml</th>\n",
       "      <td>0.872016</td>\n",
       "      <td>0.590179</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.565663</td>\n",
       "      <td>-0.520006</td>\n",
       "      <td>-0.532880</td>\n",
       "      <td>-0.563591</td>\n",
       "      <td>-0.536750</td>\n",
       "      <td>-0.525495</td>\n",
       "      <td>-0.565406</td>\n",
       "      <td>-0.544325</td>\n",
       "      <td>-0.532837</td>\n",
       "      <td>-0.562474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UjMAG</th>\n",
       "      <td>-0.699550</td>\n",
       "      <td>-0.170296</td>\n",
       "      <td>-0.565663</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.933252</td>\n",
       "      <td>0.961088</td>\n",
       "      <td>0.999865</td>\n",
       "      <td>0.970124</td>\n",
       "      <td>0.954853</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.975476</td>\n",
       "      <td>0.960981</td>\n",
       "      <td>0.963415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BjMAG</th>\n",
       "      <td>-0.628226</td>\n",
       "      <td>-0.122309</td>\n",
       "      <td>-0.520006</td>\n",
       "      <td>0.933252</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.950728</td>\n",
       "      <td>0.932328</td>\n",
       "      <td>0.954006</td>\n",
       "      <td>0.947597</td>\n",
       "      <td>0.932831</td>\n",
       "      <td>0.957836</td>\n",
       "      <td>0.950694</td>\n",
       "      <td>0.885382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VjMAG</th>\n",
       "      <td>-0.641983</td>\n",
       "      <td>-0.122616</td>\n",
       "      <td>-0.532880</td>\n",
       "      <td>0.961088</td>\n",
       "      <td>0.950728</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.959432</td>\n",
       "      <td>0.997956</td>\n",
       "      <td>0.999324</td>\n",
       "      <td>0.960265</td>\n",
       "      <td>0.992178</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.894171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>usMAG</th>\n",
       "      <td>-0.698304</td>\n",
       "      <td>-0.168326</td>\n",
       "      <td>-0.563591</td>\n",
       "      <td>0.999865</td>\n",
       "      <td>0.932328</td>\n",
       "      <td>0.959432</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.968971</td>\n",
       "      <td>0.953027</td>\n",
       "      <td>0.999903</td>\n",
       "      <td>0.974515</td>\n",
       "      <td>0.959320</td>\n",
       "      <td>0.964972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gsMAG</th>\n",
       "      <td>-0.652170</td>\n",
       "      <td>-0.126491</td>\n",
       "      <td>-0.536750</td>\n",
       "      <td>0.970124</td>\n",
       "      <td>0.954006</td>\n",
       "      <td>0.997956</td>\n",
       "      <td>0.968971</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995436</td>\n",
       "      <td>0.969562</td>\n",
       "      <td>0.995887</td>\n",
       "      <td>0.997923</td>\n",
       "      <td>0.914118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rsMAG</th>\n",
       "      <td>-0.631398</td>\n",
       "      <td>-0.114022</td>\n",
       "      <td>-0.525495</td>\n",
       "      <td>0.954853</td>\n",
       "      <td>0.947597</td>\n",
       "      <td>0.999324</td>\n",
       "      <td>0.953027</td>\n",
       "      <td>0.995436</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.953909</td>\n",
       "      <td>0.988695</td>\n",
       "      <td>0.999341</td>\n",
       "      <td>0.882782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UbMAG</th>\n",
       "      <td>-0.699731</td>\n",
       "      <td>-0.170208</td>\n",
       "      <td>-0.565406</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.932831</td>\n",
       "      <td>0.960265</td>\n",
       "      <td>0.999903</td>\n",
       "      <td>0.969562</td>\n",
       "      <td>0.953909</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.975035</td>\n",
       "      <td>0.960155</td>\n",
       "      <td>0.964189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BbMAG</th>\n",
       "      <td>-0.659506</td>\n",
       "      <td>-0.130680</td>\n",
       "      <td>-0.544325</td>\n",
       "      <td>0.975476</td>\n",
       "      <td>0.957836</td>\n",
       "      <td>0.992178</td>\n",
       "      <td>0.974515</td>\n",
       "      <td>0.995887</td>\n",
       "      <td>0.988695</td>\n",
       "      <td>0.975035</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992127</td>\n",
       "      <td>0.925047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VnMAG</th>\n",
       "      <td>-0.641870</td>\n",
       "      <td>-0.122546</td>\n",
       "      <td>-0.532837</td>\n",
       "      <td>0.960981</td>\n",
       "      <td>0.950694</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.959320</td>\n",
       "      <td>0.997923</td>\n",
       "      <td>0.999341</td>\n",
       "      <td>0.960155</td>\n",
       "      <td>0.992127</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.893972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S280MAG</th>\n",
       "      <td>-0.700453</td>\n",
       "      <td>-0.169344</td>\n",
       "      <td>-0.562474</td>\n",
       "      <td>0.963415</td>\n",
       "      <td>0.885382</td>\n",
       "      <td>0.894171</td>\n",
       "      <td>0.964972</td>\n",
       "      <td>0.914118</td>\n",
       "      <td>0.882782</td>\n",
       "      <td>0.964189</td>\n",
       "      <td>0.925047</td>\n",
       "      <td>0.893972</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Mcz     e.Mcz     MCzml     UjMAG     BjMAG     VjMAG     usMAG  \\\n",
       "Mcz      1.000000  0.613071  0.872016 -0.699550 -0.628226 -0.641983 -0.698304   \n",
       "e.Mcz    0.613071  1.000000  0.590179 -0.170296 -0.122309 -0.122616 -0.168326   \n",
       "MCzml    0.872016  0.590179  1.000000 -0.565663 -0.520006 -0.532880 -0.563591   \n",
       "UjMAG   -0.699550 -0.170296 -0.565663  1.000000  0.933252  0.961088  0.999865   \n",
       "BjMAG   -0.628226 -0.122309 -0.520006  0.933252  1.000000  0.950728  0.932328   \n",
       "VjMAG   -0.641983 -0.122616 -0.532880  0.961088  0.950728  1.000000  0.959432   \n",
       "usMAG   -0.698304 -0.168326 -0.563591  0.999865  0.932328  0.959432  1.000000   \n",
       "gsMAG   -0.652170 -0.126491 -0.536750  0.970124  0.954006  0.997956  0.968971   \n",
       "rsMAG   -0.631398 -0.114022 -0.525495  0.954853  0.947597  0.999324  0.953027   \n",
       "UbMAG   -0.699731 -0.170208 -0.565406  0.999986  0.932831  0.960265  0.999903   \n",
       "BbMAG   -0.659506 -0.130680 -0.544325  0.975476  0.957836  0.992178  0.974515   \n",
       "VnMAG   -0.641870 -0.122546 -0.532837  0.960981  0.950694  0.999997  0.959320   \n",
       "S280MAG -0.700453 -0.169344 -0.562474  0.963415  0.885382  0.894171  0.964972   \n",
       "\n",
       "            gsMAG     rsMAG     UbMAG     BbMAG     VnMAG   S280MAG  \n",
       "Mcz     -0.652170 -0.631398 -0.699731 -0.659506 -0.641870 -0.700453  \n",
       "e.Mcz   -0.126491 -0.114022 -0.170208 -0.130680 -0.122546 -0.169344  \n",
       "MCzml   -0.536750 -0.525495 -0.565406 -0.544325 -0.532837 -0.562474  \n",
       "UjMAG    0.970124  0.954853  0.999986  0.975476  0.960981  0.963415  \n",
       "BjMAG    0.954006  0.947597  0.932831  0.957836  0.950694  0.885382  \n",
       "VjMAG    0.997956  0.999324  0.960265  0.992178  0.999997  0.894171  \n",
       "usMAG    0.968971  0.953027  0.999903  0.974515  0.959320  0.964972  \n",
       "gsMAG    1.000000  0.995436  0.969562  0.995887  0.997923  0.914118  \n",
       "rsMAG    0.995436  1.000000  0.953909  0.988695  0.999341  0.882782  \n",
       "UbMAG    0.969562  0.953909  1.000000  0.975035  0.960155  0.964189  \n",
       "BbMAG    0.995887  0.988695  0.975035  1.000000  0.992127  0.925047  \n",
       "VnMAG    0.997923  0.999341  0.960155  0.992127  1.000000  0.893972  \n",
       "S280MAG  0.914118  0.882782  0.964189  0.925047  0.893972  1.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "galaxies[preds].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These various magnitude columns all have high correlations **with one another**! Let's try a simple model with just the S280MAG column, since it has the highest correlation with Mcz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = galaxies['S280MAG']\n",
    "y = galaxies['Mcz']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we only have one predictor, we can visualize the correlation with the target! We can also reshape it for modeling purposes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_rev = x.values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mpl.pyplot.scatter(x_rev, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_rev, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
       "                  n_estimators=50, random_state=42)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abr = AdaBoostRegressor(random_state=42)\n",
    "\n",
    "abr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.50416011, 0.51277109, 0.58225908, 0.47066606, 0.58004547])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(abr, x_test, y_test, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n",
    "\n",
    "Let's see if we can do better by trying different hyperparameter values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(estimator=abr,\n",
    "                 param_grid={\n",
    "                     'n_estimators': [25, 50, 100],\n",
    "                     'loss': ['linear', 'square']\n",
    "                 }, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=AdaBoostRegressor(base_estimator=None, learning_rate=1.0,\n",
       "                                         loss='linear', n_estimators=50,\n",
       "                                         random_state=42),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'loss': ['linear', 'square'],\n",
       "                         'n_estimators': [25, 50, 100]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': 'linear', 'n_estimators': 25}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression or Classification?\n",
    "\n",
    "What does my target look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "galaxies['Mcz'].hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seems to be a bit of a bimodal shape here. We might therefore try predicting whether the redshift factor is likely to be greater or less than 0.5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "galaxies['bool'] = galaxies['Mcz'] > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train2, x_test2, y_train2, y_test2 = train_test_split(x_rev, galaxies['bool'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
       "                   n_estimators=50, random_state=42)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc = AdaBoostClassifier(random_state=42)\n",
    "\n",
    "abc.fit(x_train2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8837209302325582"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc.score(x_test2, y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9130434782608695"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test2, abc.predict(x_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9402985074626866"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test2, abc.predict(x_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
       "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "                           max_features=None, max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=1, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                           n_iter_no_change=None, presort='deprecated',\n",
       "                           random_state=42, subsample=1.0, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=0,\n",
       "                           warm_start=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "gbc.fit(x_test2, y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9174418604651163"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc.score(x_test2, y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9260312944523471"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test2, gbc.predict(x_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9716417910447761"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test2, gbc.predict(x_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[138,  52],\n",
       "       [ 19, 651]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test2, gbc.predict(x_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
